{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ec23d-8d6f-4fb5-bca0-2aa5c9d7cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    sys.path.index(str(Path.cwd().parent / 'src'))\n",
    "except ValueError:\n",
    "    sys.path.insert(0, str(Path.cwd().parent / 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7371b1-80cc-45a1-b632-4584f755bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d19021-615a-4ab6-a945-2b579254410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import librosa\n",
    "from librosa.display import specshow\n",
    "from librosa.filters import get_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96601739-7386-4579-a9f0-bacd6bde74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modules.harmonic_oscillator import OscillatorBank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93a4cf-038c-4d41-b8ae-b968ae376028",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_harmonics = 60\n",
    "sample_rate = 16000\n",
    "win_length = 1024\n",
    "hop_length = 64\n",
    "f0 = 110.\n",
    "dur = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0882ea1c-fd15-4ff0-b76a-33e6aab18118",
   "metadata": {},
   "outputs": [],
   "source": [
    "osc = OscillatorBank(n_harmonics, sample_rate, hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae19227-5215-4bb0-ba33-21acc2d628b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    dist = torch.abs(torch.randn(1, 1, n_harmonics))\n",
    "    dist = torch.tile(dist, (1, dur, 1))\n",
    "    \n",
    "    # dist = 61. - torch.arange(1, 61)\n",
    "    \n",
    "    # dist = torch.ones(1, dur, 60)\n",
    "    \n",
    "    dist /= dist.sum(-1, keepdim=True)\n",
    "    amp = 0.9\n",
    "    freq = (torch.sin(torch.linspace(0, hop_length * dur / sample_rate, dur) * 3.14159265 * 0.5).unsqueeze(0).unsqueeze(-1) + 2) * f0 / 3\n",
    "    freq = torch.tile(freq, (2, 1, 1))\n",
    "    \n",
    "    # freq = torch.ones(2, dur, 1) * f0\n",
    "    audio = osc(\n",
    "        freq,\n",
    "        torch.ones(1, dur, 1) * amp,\n",
    "        dist\n",
    "    ).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e645e0-a8a8-43d5-9ca0-37dbb63a7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ee3e9-61d9-40f1-9389-d900786a8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=audio[0].T, rate=sample_rate, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27565a1-4c15-4176-904c-18b3761f8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "stft = np.abs(librosa.stft(audio[0, ..., 0].numpy(), win_length, hop_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa8590-cd9d-41e4-ad00-8d891438b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "specshow(librosa.amplitude_to_db(stft), sr=sample_rate, hop_length=hop_length)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0787e1b4-1767-4e71-b069-061b40f59835",
   "metadata": {},
   "source": [
    "- frequency is in cycles per sample\n",
    "- nyquist of win_length divided by nyquist of sample_rate is the frequency conversion factor\n",
    "- f0 * this_factor is the frequency term in fbsp kernel\n",
    "- given crepe pitch, learn inharmonicity factor by maximizing real sound's total energy in this new transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f1be9-ea91-4142-a45e-24d6ae181e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_audio(x, win_length, hop_length, strict=True):\n",
    "    # x.shape = [batch, channel, dummy, time]\n",
    "    # This pads audio so that the middle of the fft windows is on the middle of audio frames.\n",
    "    length = x.shape[-1]\n",
    "    if length % hop_length != 0:\n",
    "        if strict:\n",
    "            raise ValueError('In strict mode, audio length must be a multiple of hop length')\n",
    "        else:\n",
    "            padding_right = hop_length - length % hop_length\n",
    "            x = F.pad(x, (0, padding_right))\n",
    "    \n",
    "    padding = (win_length - hop_length) // 2\n",
    "    x = F.pad(x, (padding, padding))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae56ea0-43be-4e4f-becf-ff29134c45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_audio_basic(x, win_length, hop_length, strict=True):\n",
    "    # x.shape = [batch, channel, dummy, time]\n",
    "    # This pads audio so that the middle of the first fft window is on the beginning of the audio.\n",
    "    length = x.shape[-1]\n",
    "    if length % hop_length != 0:\n",
    "        if strict:\n",
    "            raise ValueError('In strict mode, audio length must be a multiple of hop length')\n",
    "        else:\n",
    "            padding_right = hop_length - length % hop_length\n",
    "            x = F.pad(x, (0, padding_right))\n",
    "    \n",
    "    padding_left = win_length // 2\n",
    "    padding_right = win_length // 2 - hop_length\n",
    "    x = F.pad(x, (padding_left, padding_right))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23b099-cd17-4845-87ca-a81fd779fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fbsp_matrix(f0: torch.Tensor, n_harmonics: int, win_length: int, sample_rate: int, fb: float = 1, m: int = 1):\n",
    "    # f0.shape = [batch, time, channel]\n",
    "    # matrix.shape = [batch, time, n, k]\n",
    "    # to avoid looping over all time-steps, we'll do all calculations without cutting off frequencies above nyquist.\n",
    "    # we'll zero them out during the actual transformation\n",
    "    n = torch.arange(win_length, dtype=torch.float32)\n",
    "    k = torch.arange(1, n_harmonics + 1, dtype=torch.float32)\n",
    "    fc = torch.einsum('ijk,k->ijk', f0, k) / sample_rate\n",
    "    \n",
    "    sqrt_fb = torch.sqrt(torch.tensor(fb, dtype=torch.float32))\n",
    "    order_m = (n * fb / m) ** m\n",
    "    fc_n = torch.einsum('ijk,l->ijkl', fc, n)\n",
    "    exp = torch.exp(2j * np.pi * fc_n)\n",
    "    result = sqrt_fb * torch.einsum('l,ijkl->ijkl', order_m, exp)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83aad02-8b20-498b-b45c-89aab9ac7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbsp = generate_fbsp_matrix(freq, n_harmonics, win_length, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e748e711-bedf-49cb-aa09-8b7cc6920b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to [batch, channel, dummy, time for padding and framing\n",
    "_audio = audio.permute(0, 2, 1).unsqueeze(-2)\n",
    "padded_audio = pad_audio(_audio, win_length, hop_length)\n",
    "audio_frames = F.unfold(padded_audio, (1, win_length), stride=(1, hop_length))\n",
    "hann = torch.hann_window(win_length)\n",
    "windowed_frames = torch.einsum('bnt,n->bnt', audio_frames, hann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db033a98-2e02-410d-a942-1ae61a73828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_frames.shape, fbsp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938aa4cb-e033-4969-8c31-9c13d7a507f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = torch.einsum('bnt,bthn->bth', windowed_frames.type(torch.complex64), fbsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa6b08-2717-4120-ad46-b3c6ffbfe4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dist = torch.abs(transformed) / torch.sum(torch.abs(transformed), dim=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f184cb2-7028-44aa-9454-84ea33b4e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_dist[0].flip(1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857e7e8-9870-40b7-a25c-726ce60ff58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # freq = torch.ones(2, dur, 1) * f0\n",
    "    new_audio = osc(\n",
    "        freq,\n",
    "        torch.ones(1, dur, 1) * amp,\n",
    "        new_dist\n",
    "    ).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d18f57-a44b-41fc-913c-08597ecf4adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=new_audio[0].T, rate=16000, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c5b84c-019f-4d62-8f58-4ada23ef0cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dft_kernel(n, k):\n",
    "    return torch.exp(torch.tensor(-2j * np.pi * (k / win_length) * n, dtype=torch.complex64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c8d5d-b71d-407d-8057-955696c21c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_dft_kernel(n, k, f0=f0):\n",
    "    k += 1\n",
    "    return torch.exp(torch.tensor(-2j * np.pi * (f0 * k / sample_rate) * n, dtype=torch.complex64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac820f-033f-4154-b36b-d7fe3495b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbsp_kernel(n, k, f0=f0, fb=1, m=1):\n",
    "    k += 1\n",
    "    return torch.sqrt(torch.tensor(fb, dtype=torch.float32)) * torch.tensor((fb * n / m) ** m, dtype=torch.float32) * torch.exp(torch.tensor(2j * np.pi * (f0 * k / sample_rate) * n, dtype=torch.complex64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e692bc91-955d-4ca9-a73b-0fdf73840ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "overtones = f0 * np.arange(1, n_harmonics + 1)\n",
    "overtones = overtones[overtones < sample_rate / 2]\n",
    "n_overtones = len(overtones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5b589b-1742-421d-8b30-380f6d16c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.fromfunction(dft_kernel, (win_length, win_length))\n",
    "fkernel = np.fromfunction(fbsp_kernel, (win_length, n_overtones))\n",
    "skernel = np.fromfunction(selective_dft_kernel, (win_length, n_overtones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383427bb-fa9b-4ec0-8675-43e475098fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = (0j + audio[:, win_length*8:win_length*9, 0]) @ fkernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aa4e6b-9b8f-4cb2-a7e7-69254cddec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio[:, win_length*8:win_length*9, 0].shape, fkernel.shape, tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a202766-b7b0-4f91-bd41-a133741be7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trein = torch.einsum('bi,ij->bj', (0j + audio[:, win_length*8:win_length*9, 0]), fkernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657df294-e904-42dc-b15c-82b71788d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_audio = F.pad(audio, (win_length // 2, win_length // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb045dc-c85d-4451-a48b-64f2a16c825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hann = torch.hann_window(win_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5059790-37b8-46e9-9c54-73eca88f1f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "atr = torch.abs(tr[0])\n",
    "bins = atr / torch.sum(atr)\n",
    "diff = dist[0, 0] - bins\n",
    "diff.mean(), diff.std(), bins.min(), bins.max(), dist.min(), dist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bacafb-bccd-495e-90fe-3ab8616e7b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_audio[:, win_length*i:win_length*(i+1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d3476c-798f-49c4-aee5-8710d42441dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f20a14d-69ef-476b-8a90-69154bb62824",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_length*i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a34ca95-78a5-4c1c-a258-87e18c4f529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_length*(i+1) - win_length*i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d652382-f4a2-441e-bd20-40f57ec0e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_audio.shape[1] - audio.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b9628b-d553-42b8-a754-099266383c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76d797-1a43-40f6-87f3-bb4b2aace7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fbsp_matrix(f0: torch.Tensor, n_harmonics: int, win_length: int, sample_rate: int, fb: int = 1, m: int = 1):\n",
    "    # f0.shape = [batch, time, value]\n",
    "    # matrix.shape = [batch, time, n, k]\n",
    "    # to avoid looping over all time-steps, we'll do all calculations without cutting off frequencies above nyquist.\n",
    "    # we'll zero them out during the actual transformation\n",
    "    n = torch.arange(win_length, dtype=torch.float32)\n",
    "    k = torch.arange(1, n_harmonics + 1, dtype=torch.float32)\n",
    "    fc = torch.einsum('ijk,k->ijk', f0, k)\n",
    "    left = torch.sqrt(torch.tensor(fb, dtype=torch.float32)) * (n * fb / m) ** m\n",
    "    right = torch.exp(2j * np.pi * torch.einsum('ijk,l->ijlk', fc, n))\n",
    "    print(left.shape, right.shape)\n",
    "    return torch.einsum('k,ijkl->ijkl', left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89bd806-9d0a-430f-a709-82d3d5336ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = torch.ones(1, 10, 1) * 110.\n",
    "generate_fbsp_matrix(f0, n_harmonics, win_length, sample_rate).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2637a4-a62a-42ae-a586-314f0af4aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = torch.arange(win_length)\n",
    "k = torch.arange(1, n_harmonics + 1)\n",
    "nk = torch.stack(torch.meshgrid(n, k, indexing='ij'), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff20c1-de33-4d1f-b692-ebb34abc7fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.shape, k.shape, nk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc449e-b99c-47bc-b786-b40e8af90700",
   "metadata": {},
   "outputs": [],
   "source": [
    "_nk = nk.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ff0aa-2c85-4b33-8af0-da188890fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_nk.shape, f0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b18e6-dbff-4d2d-9beb-83c99b493a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.einsum('abijk,abk->abijk', nk.unsqueeze(0).unsqueeze(0)[..., 1:], f0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c6cc91-1bb4-46d4-a44c-16f9b17a81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = (torch.sin(torch.linspace(0, hop_length * dur / sample_rate, dur) * 3.14159265 * 0.5).unsqueeze(0).unsqueeze(-1) + 1) * 110.\n",
    "n = torch.arange(win_length)\n",
    "k = torch.arange(1, n_harmonics + 1)\n",
    "# fc = f0 * k.view(1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2479e4-485e-45cf-9611-828ff6d9d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_matrix = torch.cartesian_prod(n, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90bbce-7d86-4bf9-902e-303c4478d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022f2f0-fe55-45b1-8c3b-226daa19ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b932df8-a947-49f1-b0b7-813abeef4add",
   "metadata": {},
   "source": [
    "```python\n",
    "def smooth(x, filter_size=3):\n",
    "    \"\"\"Smooth 1-d signal with a box filter.\"\"\"\n",
    "    x = tf.convert_to_tensor(x, tf.float32)\n",
    "    is_2d = len(x.shape) == 2\n",
    "    x = x[:, :, tf.newaxis] if is_2d else x[tf.newaxis, :, tf.newaxis]\n",
    "    w = tf.ones([filter_size])[:, tf.newaxis, tf.newaxis] / float(filter_size)\n",
    "    y = tf.nn.conv1d(x, w, stride=1, padding='SAME')\n",
    "    y = y[:, :, 0] if is_2d else y[0, :, 0]\n",
    "    return y.numpy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae622ff3-47e1-42eb-92ad-e594790b3bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
