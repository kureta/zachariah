{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "from librosa.display import specshow, waveshow\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f2ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modules.dsp import HarmonicOscillator, FilteredNoise\n",
    "from models.modules.loss import Loudness, CrepeFeaturesAndCents\n",
    "from models.modules.utils import pad_audio, get_frames\n",
    "from models.modules.crepe import cents_to_frequency, bins_to_cents, PITCH_BINS\n",
    "from models.modules.controller import Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 16000\n",
    "window_length = 1024\n",
    "hop_length = 64\n",
    "n_harmonics = 64\n",
    "n_bands = 128\n",
    "n_channels = 2\n",
    "time_steps = 1000\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "osc = HarmonicOscillator(sample_rate, hop_length, n_harmonics, n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pitch_1 = torch.linspace(55, 440, time_steps)\n",
    "base_pitch_2 = torch.linspace(55.1, 441, time_steps)\n",
    "base_pitch = torch.concat([base_pitch_1[None, :, None], base_pitch_2[None, :, None]], -1)\n",
    "base_pitch = torch.tile(base_pitch, (batch_size, 1, 1))\n",
    "amplitude = torch.ones(batch_size, time_steps, n_channels)\n",
    "\n",
    "harmonic_distribution = []\n",
    "for _ in range(n_harmonics):\n",
    "    envelop_1 = torch.sin(torch.linspace(0, np.random.uniform() * 40, time_steps)) + 1\n",
    "    envelop_2 = torch.sin(torch.linspace(0, np.random.uniform() * 40, time_steps)) + 1\n",
    "    envelop = torch.concat([envelop_1[None, :, None, None], envelop_2[None, :, None, None]], 2)\n",
    "    harmonic_distribution.append(envelop)\n",
    "\n",
    "harmonic_distribution = torch.concat(harmonic_distribution, dim=-1)\n",
    "harmonic_distribution = torch.tile(harmonic_distribution, (batch_size, 1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914395d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y = osc(base_pitch, amplitude, harmonic_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f913c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = y[0].numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f90b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveshow(y_np, sr=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c064c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(y_np, rate=sample_rate, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8342346",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = FilteredNoise(sample_rate, window_length, hop_length, n_bands, n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3742f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bands = []\n",
    "for _ in range(n_bands):\n",
    "    envelop_1 = torch.cos(torch.linspace(0, np.random.uniform() * 40, time_steps)) + 1\n",
    "    envelop_2 = torch.cos(torch.linspace(0, np.random.uniform() * 40, time_steps)) + 1\n",
    "    envelop = torch.concat([envelop_1[None, :, None, None], envelop_2[None, :, None, None]], 2) / (2 ** 5)\n",
    "    filter_bands.append(envelop)\n",
    "\n",
    "filter_bands = torch.concat(filter_bands, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bfd346",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = noise(filter_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471f1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = y[0, :].numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c71232",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveshow(y_np, sr=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(y_np, rate=sample_rate, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35a3005",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53bf484",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = Loudness(window_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b63a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = Path('/home/kureta/Music/cello/Cello Samples/BrahmsSonata1-00110-.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_audio, _ = librosa.load(sample_path, sr=sample_rate, mono=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(np_audio, rate=sample_rate, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b255d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = np_audio.T\n",
    "audio = torch.from_numpy(audio[None, :, :])\n",
    "audio = pad_audio(audio, window_length, hop_length, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51814fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = get_frames(audio, window_length, hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd066bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten frames\n",
    "batch, n_frames, n_channels, window_length = frames.shape\n",
    "flat_frames = rearrange(frames, 'b f c w -> (b f c) w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte rms\n",
    "loudness = rms(flat_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00046a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unflatten loudness\n",
    "loudness = rearrange(loudness, '(b f c) -> b f c', b=batch, f=n_frames, c=n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loudness[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crepe = CrepeFeaturesAndCents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad606554",
   "metadata": {},
   "outputs": [],
   "source": [
    "cents, features = crepe(flat_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cents = rearrange(cents, '(b f c) 1 -> b f c', b=batch, f=n_frames, c=n_channels)\n",
    "features = rearrange(features, '(b f c) x y 1 -> b f c (x y)', b=batch, f=n_frames, c=n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99947f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cents[0])\n",
    "plt.ylim(5200, 7000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eafbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = cents_to_frequency(cents)\n",
    "amps = loudness * 5.0\n",
    "overtones = torch.zeros(*f0.shape, n_harmonics)\n",
    "overtones[:, :, :, 0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = osc(f0, amps, overtones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = y[0].numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198903b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(y_np, rate=sample_rate, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = np_audio.T\n",
    "audio = torch.from_numpy(audio[None, :, :])\n",
    "audio = pad_audio(audio, sample_rate*2, sample_rate, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2dd915",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = get_frames(audio, sample_rate*2, sample_rate)[0].transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = get_frames(batches, window_length, hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e4f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl = Controller(n_harmonics, n_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac1f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6433deba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl = ctrl.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b12f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = rms.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "crepe = crepe.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "osc = osc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a9370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten frames\n",
    "batch, n_frames, n_channels, window_length = frames.shape\n",
    "flat_frames = rearrange(frames, 'b f c w -> (b f c) w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833c593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte rms\n",
    "loudness = rms(flat_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56183aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unflatten loudness\n",
    "loudness = rearrange(loudness, '(b f c) -> b f c', b=batch, f=n_frames, c=n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92079db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cents, features = crepe(flat_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cents = rearrange(cents, '(b f c) 1 -> b f c', b=batch, f=n_frames, c=n_channels)\n",
    "features = rearrange(features, '(b f c) x y 1 -> b f c (x y)', b=batch, f=n_frames, c=n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53344044",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch = (cents - bins_to_cents(0)) / bins_to_cents(PITCH_BINS-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c96261",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(ctrl.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6644990",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch.shape, loudness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f4368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_pitch = rearrange(pitch, 'b t c -> (b c) t 1')\n",
    "flat_loudness = rearrange(loudness, 'b t c -> (b c) t 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e089b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = cents_to_frequency(cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    # Zero your gradients for every batch!\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Make predictions for this batch\n",
    "    (_, amps, overtones), _ = ctrl(flat_pitch, flat_loudness)\n",
    "    amps = rearrange(amps, '(b c) t 1 -> b t c', c=2)\n",
    "    overtones = rearrange(overtones, '(b c) t o -> b t c o', c=2)\n",
    "    sound = osc(f0, amps, overtones)\n",
    "    sound = pad_audio(sound, window_length, hop_length)\n",
    "    \n",
    "    p_frames = get_frames(sound, window_length, hop_length)\n",
    "    p_flat_frames = rearrange(p_frames, 'b f c w -> (b f c) w')\n",
    "    \n",
    "    _, p_features = crepe(p_flat_frames)\n",
    "    p_loudness = rms(flat_frames)\n",
    "    p_loudness = rearrange(p_loudness, '(b f c) -> b f c', b=8, c=2)\n",
    "    p_features = rearrange(p_features, '(b f c) x y 1 -> b f c (x y)', b=8, c=2)\n",
    "\n",
    "    # Compute the loss and its gradients\n",
    "    feature_loss = F.mse_loss(features, p_features)\n",
    "    loudness_loss = F.mse_loss(loudness, p_loudness)\n",
    "    loss = feature_loss + loudness_loss\n",
    "    loss.backward()\n",
    "\n",
    "    # Adjust learning weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcb98cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
